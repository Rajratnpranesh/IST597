{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IST597_MLP_Raj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnkurMali/IST597_Spring_2022/blob/main/IST597_MLP_collab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71kdFp0QgF4K"
      },
      "source": [
        "# IST597:- Multi-Layer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case 1: \n",
        "\n",
        "Using default batch size without softmax activation in output layer, without any regularization to determine the Categorical Cross-Entropy of test dataset and determine the accuracy of default model in GPU,TPU,CPU and on default mode."
      ],
      "metadata": {
        "id": "rVS3rMVhgV4m"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2yHcl5xgPV1"
      },
      "source": [
        "## Load the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DPwxLR2gSLC"
      },
      "source": [
        "#Core Libraries \n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "#Libraries for data featching\n",
        "from sklearn.datasets import fetch_openml\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "np.random.seed(5997)\n",
        "tf.random.set_seed(5997)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "x = (x/255).astype('float32')\n",
        "y = to_categorical(y)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=42)"
      ],
      "metadata": {
        "id": "B1WSN1MJ3X4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV-3kEaggcO8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a2b7cff-3797-4511-83d5-585067d4b68a"
      },
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw78jw6pDqSM"
      },
      "source": [
        "#Get number of Gpu's and id's in the system or else you can also use Nvidia-smi in command prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Dk_S2TMg_6_"
      },
      "source": [
        "## Define the input layer size, hidden layers size and output layer size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40XlFnwho7D8"
      },
      "source": [
        "size_input = 784\n",
        "size_hidden = [128,64]\n",
        "size_output = 10\n",
        "number_of_train_examples = 60000\n",
        "number_of_test_examples = 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aigqKFFF5BM2"
      },
      "source": [
        "# Split dataset into batches\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(16)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb4hOoVbnzSJ"
      },
      "source": [
        "## Build MLP using Eager Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht9_qpYipgHw"
      },
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_hidden, size_output, device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer-1\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden[0]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden[0]]))\n",
        "\n",
        "    # Initialize weights between hidden layer-1 and hidden layer-2\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden[0], self.size_hidden[1]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden[1]]))\n",
        "\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden[1], self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
        "    \n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.keras.losses.CategoricalCrossentropy()(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    # Compute values in hidden layer1\n",
        "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat1 = tf.nn.relu(what1)\n",
        "    # Compute values in hidden layer2\n",
        "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    hhat2 = tf.nn.relu(what2)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat2, self.W3) + self.b3\n",
        "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
        "    #Second add tf.Softmax(output) and then return this variable\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUDFOuNk618X"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZPVUu0YDa-_"
      },
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moAeRMJ56kr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5f635b6-4b26-4fbc-fb05-0287f9622348"
      },
      "source": [
        "# Initialize model using CPU\n",
        "mlp_on_cpu = MLP(size_input, size_hidden, size_output, device='cpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_a = tf.zeros([], dtype=tf.float32) #tensor for accumulating accuracy\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(25, seed=epoch*(5997)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    # Calculate accuracy\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    pred = tf.nn.softmax(preds)\n",
        "    outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "    pred = tf.cast(pred, dtype=tf.float32)\n",
        "    correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "\n",
        "\n",
        "    accuracy_a = accuracy_a + accuracy\n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Categorical_Cross-Entropy:= {}'.format(epoch + 1, np.sum(loss_total) / x_train.shape[0]))\n",
        "  print('Number of Epoch = {} - Accuracy:= {}'.format(epoch + 1, (np.sum(accuracy_a) / x_train.shape[0])*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Categorical_Cross-Entropy:= 0.2540452337184874\n",
            "Number of Epoch = 1 - Accuracy:= 0.4616836163176208\n",
            "Number of Epoch = 2 - Categorical_Cross-Entropy:= 0.247548959427521\n",
            "Number of Epoch = 2 - Accuracy:= 0.4713471741235557\n",
            "Number of Epoch = 3 - Categorical_Cross-Entropy:= 0.24297213103991597\n",
            "Number of Epoch = 3 - Accuracy:= 0.4810948988970588\n",
            "Number of Epoch = 4 - Categorical_Cross-Entropy:= 0.2380863149947479\n",
            "Number of Epoch = 4 - Accuracy:= 0.4897495814732143\n",
            "Number of Epoch = 5 - Categorical_Cross-Entropy:= 0.22200520286239495\n",
            "Number of Epoch = 5 - Accuracy:= 0.5048750164128152\n",
            "Number of Epoch = 6 - Categorical_Cross-Entropy:= 0.20988084296218487\n",
            "Number of Epoch = 6 - Accuracy:= 0.503530704273897\n",
            "Number of Epoch = 7 - Categorical_Cross-Entropy:= 0.1993276162027311\n",
            "Number of Epoch = 7 - Accuracy:= 0.5033629858193277\n",
            "Number of Epoch = 8 - Categorical_Cross-Entropy:= 0.19061667870273108\n",
            "Number of Epoch = 8 - Accuracy:= 0.5072281524914654\n",
            "Number of Epoch = 9 - Categorical_Cross-Entropy:= 0.18626784073004202\n",
            "Number of Epoch = 9 - Accuracy:= 0.5097490583147322\n",
            "Number of Epoch = 10 - Categorical_Cross-Entropy:= 0.18421615677521008\n",
            "Number of Epoch = 10 - Accuracy:= 0.5122703231683299\n",
            "\n",
            "Total time taken (in seconds): 722.28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdMFAuH18Ve0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28879956-9a74-4353-b803-8893ef3172d2"
      },
      "source": [
        "# Initialize model using GPU\n",
        "mlp_on_gpu = MLP(size_input, size_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_a = tf.zeros([], dtype=tf.float32) #tensor for accumulating accuracy\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(25, seed=epoch*(5997)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    pred = tf.nn.softmax(preds)\n",
        "\n",
        "\n",
        "    outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "    pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "\n",
        "\n",
        "    accuracy_a = accuracy_a + accuracy\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_gpu.loss(preds, outputs)\n",
        "    mlp_on_gpu.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Categorical Cross-Entropy:= {}'.format(epoch + 1, np.sum(loss_total_gpu) / x_train.shape[0]))\n",
        "  print('Number of Epoch = {} - Accuracy:= {}'.format(epoch + 1, (np.sum(accuracy_a) / x_train.shape[0])*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Categorical Cross-Entropy:= 0.42788383009453784\n",
            "Number of Epoch = 1 - Accuracy:= 0.52899226340927\n",
            "Number of Epoch = 2 - Categorical Cross-Entropy:= 0.4151001181722689\n",
            "Number of Epoch = 2 - Accuracy:= 0.5319335424599527\n",
            "Number of Epoch = 3 - Categorical Cross-Entropy:= 0.3966051404936975\n",
            "Number of Epoch = 3 - Accuracy:= 0.549749191668855\n",
            "Number of Epoch = 4 - Categorical Cross-Entropy:= 0.36249474789915964\n",
            "Number of Epoch = 4 - Accuracy:= 0.5327742889147846\n",
            "Number of Epoch = 5 - Categorical Cross-Entropy:= 0.34080225840336137\n",
            "Number of Epoch = 5 - Accuracy:= 0.5390756302521008\n",
            "Number of Epoch = 6 - Categorical Cross-Entropy:= 0.32490342699579833\n",
            "Number of Epoch = 6 - Accuracy:= 0.5627730169216124\n",
            "Number of Epoch = 7 - Categorical Cross-Entropy:= 0.3074765625\n",
            "Number of Epoch = 7 - Accuracy:= 0.6010082597492121\n",
            "Number of Epoch = 8 - Categorical Cross-Entropy:= 0.2927140887605042\n",
            "Number of Epoch = 8 - Accuracy:= 0.6168062610786502\n",
            "Number of Epoch = 9 - Categorical Cross-Entropy:= 0.28597016150210086\n",
            "Number of Epoch = 9 - Accuracy:= 0.6408401104582458\n",
            "Number of Epoch = 10 - Categorical Cross-Entropy:= 0.27462944787289917\n",
            "Number of Epoch = 10 - Accuracy:= 0.6700839002593225\n",
            "\n",
            "Total time taken (in seconds): 625.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Default mode\n",
        "mlp_on_default = MLP(size_input, size_hidden, size_output)\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_a = tf.zeros([], dtype=tf.float32)\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(25, seed=epoch*(5997)).batch(150)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_default.forward(inputs)\n",
        "    pred = tf.nn.softmax(preds)  # Applying softmax to logits to get better accuracy\n",
        "\n",
        "\n",
        "    outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "    pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "\n",
        "\n",
        "    accuracy_a = accuracy_a + accuracy\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_default.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_default.loss(preds, outputs)\n",
        "    mlp_on_default.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Categorical Cross-Entropy:= {}'.format(epoch + 1, np.sum(loss_total_gpu) / x_train.shape[0]))\n",
        "  print('Number of Epoch = {} - Accuracy:= {}'.format(epoch + 1, (np.sum(accuracy_a) / x_train.shape[0])*1000))\n",
        "time_taken = time.time() - time_start\n",
        "print('\\n')\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc36a420-a5ee-4d2d-a5be-067ab737f33f",
        "id": "7QCntvyFt2s2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Categorical Cross-Entropy:= 0.029009708180147056\n",
            "Number of Epoch = 1 - Accuracy:= 0.5672555426589581\n",
            "Number of Epoch = 2 - Categorical Cross-Entropy:= 0.02849617171087185\n",
            "Number of Epoch = 2 - Accuracy:= 0.5738382881228663\n",
            "Number of Epoch = 3 - Categorical Cross-Entropy:= 0.0281072003019958\n",
            "Number of Epoch = 3 - Accuracy:= 0.5773509367614233\n",
            "Number of Epoch = 4 - Categorical Cross-Entropy:= 0.027478581276260506\n",
            "Number of Epoch = 4 - Accuracy:= 0.5914010697052258\n",
            "Number of Epoch = 5 - Categorical Cross-Entropy:= 0.02647882336528361\n",
            "Number of Epoch = 5 - Accuracy:= 0.5989332154859014\n",
            "Number of Epoch = 6 - Categorical Cross-Entropy:= 0.0253718938747374\n",
            "Number of Epoch = 6 - Accuracy:= 0.59819054983443573\n",
            "Number of Epoch = 7 - Categorical Cross-Entropy:= 0.02454001444327731\n",
            "Number of Epoch = 7 - Accuracy:= 0.6128578904095819\n",
            "Number of Epoch = 8 - Categorical Cross-Entropy:= 0.023555405560661765\n",
            "Number of Epoch = 8 - Accuracy:= 0.61438934459526\n",
            "Number of Epoch = 9 - Categorical Cross-Entropy:= 0.02241018497242647\n",
            "Number of Epoch = 9 - Accuracy:= 0.618518989883551\n",
            "Number of Epoch = 10 - Categorical Cross-Entropy:= 0.02157053817620798\n",
            "Number of Epoch = 10 - Accuracy:= 0.6209810388388754\n",
            "\n",
            "\n",
            "Total time taken (in seconds): 790.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "accuracy_a = tf.zeros([], dtype=tf.float32)\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_default.forward(inputs)\n",
        "\n",
        "  pred = preds\n",
        "  outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "  pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "  correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  accuracy_a = accuracy_a + accuracy\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_default.loss(preds, outputs)\n",
        "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
        "# print(X_train.shape[0])\n",
        "# print(test_loss_total.numpy())\n",
        "# print(b)\n",
        "print('Test Categorical_Cross-Entropy: {:.4f}'.format(np.sum(test_loss_total.numpy()) / x_train.shape[0]))\n",
        "print('Test Accuracy: {:.4f}'.format((np.sum(accuracy_a) / x_train.shape[0])*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42991de5-c0ea-4ddc-8c16-2d2ab2cb164e",
        "id": "HVMXgsQOt2s8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Categorical_Cross-Entropy: 0.0785\n",
            "Test Accuracy: 0.6142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot"
      ],
      "metadata": {
        "id": "1sde2yiiDjbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = [0.56725,0.57383,0.57735,0.59140,0.59893,0.59819,0.61285,0.61438,0.61851,0.62098]"
      ],
      "metadata": {
        "id": "Oqe4zepst2s9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = [0.02900,0.02849,0.02849,0.02747,0.02647,0.02537,0.02454,0.02355,0.02241,0.02157]"
      ],
      "metadata": {
        "id": "TubdKMuUt2s9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Train Accuracy')\n",
        "plt.title('MNIST-784 dataset')\n",
        "plt.plot(acc)\n",
        "# plt.plot(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "kdSyr6KtD2jU",
        "outputId": "c538d616-f52f-4296-fc39-a1e1c97da509"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f98afa7d750>]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Train Loss')\n",
        "plt.title('MNIST-784 dataset')\n",
        "plt.plot(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "97a27844-e15c-4e2c-d130-4345c231068f",
        "id": "RE44WrgLt2s9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f98af78ad10>]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0nsWJvcMFS-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test values for 10 rounds"
      ],
      "metadata": {
        "id": "O-88A3n7FWPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acct = [60.37, 56.23, 58.81, 55.41, 58.45, 54.99, 56.86, 61.25, 59.34, 57.56]"
      ],
      "metadata": {
        "id": "HawFcI-WFS3-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.xlabel('Train Count')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.title('MNIST-784 dataset')\n",
        "plt.plot(acct)\n",
        "# plt.plot(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "tytKDlk4FV4J",
        "outputId": "c4f981fb-0c9a-40d4-b67b-6736cccc6083"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f98af8b3dd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case 2\n",
        "\n",
        "In this case, the implementation is done using an additional layer of softmax on the top of the output layer. Softmax will Using default batch size with softmax activation in output layer, without any regularization. Softmax predict a multinomial probability distribution. That is, softmax is used as the activation function for multi-class classification problems where class membership is required on more than two class labels."
      ],
      "metadata": {
        "id": "MVYHCDjN2w49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into batches\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(16)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(4)"
      ],
      "metadata": {
        "id": "yFsDyDx_3CxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_hidden, size_output, device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer-1\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden[0]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden[0]]))\n",
        "\n",
        "    # Initialize weights between hidden layer-1 and hidden layer-2\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden[0], self.size_hidden[1]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden[1]]))\n",
        "\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden[1], self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
        "    \n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.keras.losses.CategoricalCrossentropy()(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    # Compute values in hidden layer1\n",
        "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat1 = tf.nn.relu(what1)\n",
        "    # Compute values in hidden layer2\n",
        "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    hhat2 = tf.nn.relu(what2)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat2, self.W3) + self.b3\n",
        "    output = tf.keras.activations.softmax(output)\n",
        "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
        "    #Second add tf.Softmax(output) and then return this variable\n",
        "    return output"
      ],
      "metadata": {
        "id": "Y_U0O2T6DPk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10"
      ],
      "metadata": {
        "id": "P89jRHdSEa8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Default mode\n",
        "mlp_on_default = MLP(size_input, size_hidden, size_output)\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_a = tf.zeros([], dtype=tf.float32)\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(25, seed=epoch*(5997)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_default.forward(inputs)\n",
        "    pred = tf.nn.softmax(preds)  # Applying softmax to logits to get better accuracy\n",
        "\n",
        "\n",
        "    outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "    pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "\n",
        "\n",
        "    accuracy_a = accuracy_a + accuracy\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_default.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_default.loss(preds, outputs)\n",
        "    mlp_on_default.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Categorical Cross-Entropy:= {}'.format(epoch + 1, np.sum(loss_total_gpu) / x_train.shape[0]))\n",
        "  print('Number of Epoch = {} - Accuracy:= {}'.format(epoch + 1, (np.sum(accuracy_a) / x_train.shape[0])*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjuTtAtKJgmv",
        "outputId": "29695048-2664-4897-83d9-f885cbd36e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Categorical Cross-Entropy:= 0.3698112526260504\n",
            "Number of Epoch = 1 - Accuracy:= 0.489329721146271\n",
            "Number of Epoch = 2 - Categorical Cross-Entropy:= 0.36060353203781514\n",
            "Number of Epoch = 2 - Accuracy:= 0.4901695956702994\n",
            "Number of Epoch = 3 - Categorical Cross-Entropy:= 0.35689374343487396\n",
            "Number of Epoch = 3 - Accuracy:= 0.49227110277704833\n",
            "Number of Epoch = 4 - Categorical Cross-Entropy:= 0.3511022518382353\n",
            "Number of Epoch = 4 - Accuracy:= 0.4957158449317227\n",
            "Number of Epoch = 5 - Categorical Cross-Entropy:= 0.3463145351890756\n",
            "Number of Epoch = 5 - Accuracy:= 0.49747996610753675\n",
            "Number of Epoch = 6 - Categorical Cross-Entropy:= 0.3402994353991597\n",
            "Number of Epoch = 6 - Accuracy:= 0.49907759978991595\n",
            "Number of Epoch = 7 - Categorical Cross-Entropy:= 0.3206730895483193\n",
            "Number of Epoch = 7 - Accuracy:= 0.494287109375\n",
            "Number of Epoch = 8 - Categorical Cross-Entropy:= 0.310984112394958\n",
            "Number of Epoch = 8 - Accuracy:= 0.4947912392496061\n",
            "Number of Epoch = 9 - Categorical Cross-Entropy:= 0.2972127429096639\n",
            "Number of Epoch = 9 - Accuracy:= 0.5041192062762605\n",
            "Number of Epoch = 10 - Categorical Cross-Entropy:= 0.2880283285189076\n",
            "Number of Epoch = 10 - Accuracy:= 0.5055474802225578\n",
            "\n",
            "Total time taken (in seconds): 671.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "accuracy_a = tf.zeros([], dtype=tf.float32)\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_default.forward(inputs)\n",
        "\n",
        "  pred = preds\n",
        "  outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "  pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "  correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  accuracy_a = accuracy_a + accuracy\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_default.loss(preds, outputs)\n",
        "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
        "# print(X_train.shape[0])\n",
        "# print(test_loss_total.numpy())\n",
        "# print(b)\n",
        "print('Test Categorical_Cross-Entropy: {:.4f}'.format(np.sum(test_loss_total.numpy()) / x_train.shape[0]))\n",
        "print('Test Accuracy: {:.4f}'.format((np.sum(accuracy_a) / x_train.shape[0])*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X8z0Vhi0WIq",
        "outputId": "19799760-774c-480e-922e-148d572bab90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Categorical_Cross-Entropy: 0.6273\n",
            "Test Accuracy: 0.5030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case 3\n",
        "\n",
        "In this case, the implementation is done by adding a dropout layer after every MLP layer. So we have one Dropout penalty/regularization layers added after the activation of layer of each MLP layer."
      ],
      "metadata": {
        "id": "Yyml7OwiguJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into batches\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(16)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(4)"
      ],
      "metadata": {
        "id": "NH6VSpWshNaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden, self.size_output, self.dropout_layer, self.device =\\\n",
        "    size_input, size_hidden, size_output, tf.keras.layers.Dropout(rate=0.2), device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer-1\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden[0]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden[0]]))\n",
        "\n",
        "    # Initialize weights between hidden layer-1 and hidden layer-2\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden[0], self.size_hidden[1]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden[1]]))\n",
        "\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden[1], self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
        "    \n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.keras.losses.CategoricalCrossentropy()(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    # Compute values in hidden layer1\n",
        "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat1 = tf.nn.relu(what1)\n",
        "    hhat1 = self.dropout_layer(hhat1)\n",
        "    # Compute values in hidden layer2\n",
        "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    hhat2 = tf.nn.relu(what2)\n",
        "    hhat2 = self.dropout_layer(hhat2)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat2, self.W3) + self.b3\n",
        "    #output = tf.keras.activations.softmax(output)\n",
        "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
        "    #Second add tf.Softmax(output) and then return this variable\n",
        "    return output"
      ],
      "metadata": {
        "id": "E4scKXSMHIAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10"
      ],
      "metadata": {
        "id": "ujRr5_7EHuQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Default mode\n",
        "mlp_on_default = MLP(size_input, size_hidden, size_output)\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_a = tf.zeros([], dtype=tf.float32) \n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(25, seed=epoch*(5997)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_default.forward(inputs)\n",
        "    pred = tf.nn.softmax(preds)  # Applying softmax to logits to get better accuracy\n",
        "\n",
        "\n",
        "    outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "    pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "\n",
        "\n",
        "    accuracy_a = accuracy_a + accuracy\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_default.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_default.loss(preds, outputs)\n",
        "    mlp_on_default.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Categorical Cross-Entropy:= {}'.format(epoch + 1, np.sum(loss_total_gpu) / x_train.shape[0]))\n",
        "  print('Number of Epoch = {} - Accuracy:= {}'.format(epoch + 1, (np.sum(accuracy_a) / x_train.shape[0])*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aabacfd-4cb9-4bc2-a988-cb9b785f99f6",
        "id": "p0zQtGri0KAO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Categorical Cross-Entropy:= 0.08024983587184874\n",
            "Number of Epoch = 1 - Accuracy:= 0.5735574930655856\n",
            "Number of Epoch = 2 - Categorical Cross-Entropy:= 0.08018526785714286\n",
            "Number of Epoch = 2 - Accuracy:= 0.5777403887580422\n",
            "Number of Epoch = 3 - Categorical Cross-Entropy:= 0.08011497176995798\n",
            "Number of Epoch = 3 - Accuracy:= 0.582091515805541\n",
            "Number of Epoch = 4 - Categorical Cross-Entropy:= 0.08004182805934874\n",
            "Number of Epoch = 4 - Accuracy:= 0.5862928759150144\n",
            "Number of Epoch = 5 - Categorical Cross-Entropy:= 0.07997803965336134\n",
            "Number of Epoch = 5 - Accuracy:= 0.5916153723452271\n",
            "Number of Epoch = 6 - Categorical Cross-Entropy:= 0.07992221966911765\n",
            "Number of Epoch = 6 - Accuracy:= 0.5951822104574251\n",
            "Number of Epoch = 7 - Categorical Cross-Entropy:= 0.0798676552652311\n",
            "Number of Epoch = 7 - Accuracy:= 0.5986182589490874\n",
            "Number of Epoch = 8 - Categorical Cross-Entropy:= 0.07981012834821428\n",
            "Number of Epoch = 8 - Accuracy:= 0.6016997008764444\n",
            "Number of Epoch = 9 - Categorical Cross-Entropy:= 0.0797527081144958\n",
            "Number of Epoch = 9 - Accuracy:= 0.6054156006885176\n",
            "Number of Epoch = 10 - Categorical Cross-Entropy:= 0.07969765132615546\n",
            "Number of Epoch = 10 - Accuracy:= 0.6084968502781972\n",
            "\n",
            "Total time taken (in seconds): 122.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "accuracy_a = tf.zeros([], dtype=tf.float32)\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_default.forward(inputs)\n",
        "\n",
        "  pred = preds\n",
        "  outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "  pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "  correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  accuracy_a = accuracy_a + accuracy\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_default.loss(preds, outputs)\n",
        "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
        "# print(X_train.shape[0])\n",
        "# print(test_loss_total.numpy())\n",
        "# print(b)\n",
        "print('Test Categorical_Cross-Entropy: {:.4f}'.format(np.sum(test_loss_total.numpy()) / x_train.shape[0]))\n",
        "print('Test Accuracy: {:.4f}'.format((np.sum(accuracy_a) / x_train.shape[0])*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUSkRgVm0oSu",
        "outputId": "79c916c8-17d5-411f-eec4-4698256d92cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Categorical_Cross-Entropy: 0.1022\n",
            "Test Accuracy: 0.6028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case 4\n",
        "\n",
        "In this case, the implementation is done by adding regularizing function by applying L1 penalty/regularization."
      ],
      "metadata": {
        "id": "ggLjxVFZhPgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into batches\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(16)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(4)"
      ],
      "metadata": {
        "id": "-NL-s875hXtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden, self.size_output, self.dropout_layer, self.device =\\\n",
        "    size_input, size_hidden, size_output, tf.keras.layers.Dropout(rate=0.2), device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer-1\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden[0]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden[0]]))\n",
        "\n",
        "    # Initialize weights between hidden layer-1 and hidden layer-2\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden[0], self.size_hidden[1]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden[1]]))\n",
        "\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden[1], self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
        "    \n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.keras.losses.CategoricalCrossentropy()(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      L1= (tf.reduce_sum(self.W1)+ tf.reduce_sum(self.W2)+tf.reduce_sum(self.W3)) # L1 = absolute sum of weights (Also known as Lasso)\n",
        "      current_loss = self.loss(predicted, y_train) + 0.03 * L1 # Lambda/Regularization Parameter = 0.03\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    # Compute values in hidden layer1\n",
        "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat1 = tf.nn.relu(what1)\n",
        "    # hhat1 = self.dropout_layer(hhat1)\n",
        "    # Compute values in hidden layer2\n",
        "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    hhat2 = tf.nn.relu(what2)\n",
        "    # hhat2 = self.dropout_layer(hhat2)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat2, self.W3) + self.b3\n",
        "    #output = tf.keras.activations.softmax(output)\n",
        "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
        "    #Second add tf.Softmax(output) and then return this variable\n",
        "    return output"
      ],
      "metadata": {
        "id": "O6ySQ-DmZyk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10"
      ],
      "metadata": {
        "id": "1cWNHuQqbnKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Default mode\n",
        "mlp_on_default = MLP(size_input, size_hidden, size_output)\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_a = tf.zeros([], dtype=tf.float32)\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(25, seed=epoch*(5997)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_default.forward(inputs)\n",
        "    pred = tf.nn.softmax(preds)  # Applying softmax to logits to get better accuracy\n",
        "\n",
        "\n",
        "    outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "    pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(outputs, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "\n",
        "\n",
        "    accuracy_a = accuracy_a + accuracy\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_default.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_default.loss(preds, outputs)\n",
        "    mlp_on_default.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Categorical Cross-Entropy:= {}'.format(epoch + 1, np.sum(loss_total_gpu) / x_train.shape[0]))\n",
        "  print('Number of Epoch = {} - Accuracy:= {}'.format(epoch + 1, (np.sum(accuracy_a) / x_train.shape[0])*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_azRmh6NbqQf",
        "outputId": "d0bad3ec-8f15-4a9d-c160-342a48a47529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Categorical Cross-Entropy:= 0.039850729549632355\n",
            "Number of Epoch = 1 - Accuracy:= 0.5931840784409468\n",
            "Number of Epoch = 2 - Categorical Cross-Entropy:= 0.039683286009716386\n",
            "Number of Epoch = 2 - Accuracy:= 0.5939121406619289\n",
            "Number of Epoch = 3 - Categorical Cross-Entropy:= 0.039616063222163864\n",
            "Number of Epoch = 3 - Accuracy:= 0.5937256372275472\n",
            "Number of Epoch = 4 - Categorical Cross-Entropy:= 0.03951135356486345\n",
            "Number of Epoch = 4 - Accuracy:= 0.5935015638335412\n",
            "Number of Epoch = 5 - Categorical Cross-Entropy:= 0.03922808889180672\n",
            "Number of Epoch = 5 - Accuracy:= 0.5944726126534599\n",
            "Number of Epoch = 6 - Categorical Cross-Entropy:= 0.03859858357405462\n",
            "Number of Epoch = 6 - Accuracy:= 0.5987677694368764\n",
            "Number of Epoch = 7 - Categorical Cross-Entropy:= 0.03806398946297269\n",
            "Number of Epoch = 7 - Accuracy:= 0.6019235819327731\n",
            "Number of Epoch = 8 - Categorical Cross-Entropy:= 0.03746544692095588\n",
            "Number of Epoch = 8 - Accuracy:= 0.6064985259240415\n",
            "Number of Epoch = 9 - Categorical Cross-Entropy:= 0.03714058396796219\n",
            "Number of Epoch = 9 - Accuracy:= 0.6083849738625919\n",
            "Number of Epoch = 10 - Categorical Cross-Entropy:= 0.03706898716517857\n",
            "Number of Epoch = 10 - Accuracy:= 0.6109242799903164\n",
            "\n",
            "Total time taken (in seconds): 95.38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "accuracy_a = tf.zeros([], dtype=tf.float32)\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_default.forward(inputs)\n",
        "\n",
        "  pred = preds\n",
        "  outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "  pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "  correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  accuracy_a = accuracy_a + accuracy\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_default.loss(preds, outputs)\n",
        "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
        "# print(X_train.shape[0])\n",
        "# print(test_loss_total.numpy())\n",
        "# print(b)\n",
        "print('Test Categorical_Cross-Entropy: {:.4f}'.format(np.sum(test_loss_total.numpy()) / x_train.shape[0]))\n",
        "print('Test Accuracy: {:.4f}'.format((np.sum(accuracy_a) / x_train.shape[0])*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQFg8mYHyeOw",
        "outputId": "82308616-c565-4703-da1e-5353addc6e90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Categorical_Cross-Entropy: 0.0931\n",
            "Test Accuracy: 0.6011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case 5\n",
        "\n",
        "\n",
        "In this case, the implementation is done by adding regularizing function by applying L2 penalty/regularization."
      ],
      "metadata": {
        "id": "WTF1L7WXhZBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into batches\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(16)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(4)"
      ],
      "metadata": {
        "id": "oHsf3UV8h3A4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden, self.size_output, self.dropout_layer, self.device =\\\n",
        "    size_input, size_hidden, size_output, tf.keras.layers.Dropout(rate=0.2), device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer-1\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden[0]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden[0]]))\n",
        "\n",
        "    # Initialize weights between hidden layer-1 and hidden layer-2\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden[0], self.size_hidden[1]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden[1]]))\n",
        "\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden[1], self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
        "    \n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.keras.losses.CategoricalCrossentropy()(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      L2= (tf.reduce_sum(tf.square(self.W1))+ tf.reduce_sum(tf.square(self.W2))+tf.reduce_sum(tf.square(self.W3)))/3 # L2 = (absolute sum of squared weights)/no.of weights (Also known as Lasso)\n",
        "      current_loss = self.loss(predicted, y_train) + 0.03 * L2 # Lambda/Regularization Parameter = 0.03\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    # Compute values in hidden layer1\n",
        "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat1 = tf.nn.relu(what1)\n",
        "    # hhat1 = self.dropout_layer(hhat1)\n",
        "    # Compute values in hidden layer2\n",
        "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    hhat2 = tf.nn.relu(what2)\n",
        "    # hhat2 = self.dropout_layer(hhat2)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat2, self.W3) + self.b3\n",
        "    #output = tf.keras.activations.softmax(output)\n",
        "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
        "    #Second add tf.Softmax(output) and then return this variable\n",
        "    return output"
      ],
      "metadata": {
        "id": "9R3aPWRJgIEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10"
      ],
      "metadata": {
        "id": "RjadkB_ggMpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI4lsqPhB6Xi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a59c4792-70fb-4598-db09-6b073824c006"
      },
      "source": [
        "#Default mode\n",
        "mlp_on_default = MLP(size_input, size_hidden, size_output)\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_a = tf.zeros([], dtype=tf.float32) #tensor for accumulating accuracy\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(25, seed=epoch*(5997)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_default.forward(inputs)\n",
        "    pred = tf.nn.softmax(preds)\n",
        "\n",
        "\n",
        "    outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "    pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "\n",
        "\n",
        "    accuracy_a = accuracy_a + accuracy\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_default.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_default.loss(preds, outputs)\n",
        "    mlp_on_default.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Categorical Cross-Entropy:= {}'.format(epoch + 1, np.sum(loss_total_gpu) / x_train.shape[0]))\n",
        "  print('Number of Epoch = {} - Accuracy:= {}'.format(epoch + 1, (np.sum(accuracy_a) / x_train.shape[0])*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Categorical Cross-Entropy:= 0.30573391544117645\n",
            "Number of Epoch = 1 - Accuracy:= 0.4708428390887605\n",
            "Number of Epoch = 2 - Categorical Cross-Entropy:= 0.25576692161239495\n",
            "Number of Epoch = 2 - Accuracy:= 0.5183211126247373\n",
            "Number of Epoch = 3 - Categorical Cross-Entropy:= 0.2125008862920168\n",
            "Number of Epoch = 3 - Accuracy:= 0.5553782743566177\n",
            "Number of Epoch = 4 - Categorical Cross-Entropy:= 0.18682595850840336\n",
            "Number of Epoch = 4 - Accuracy:= 0.5611766654904149\n",
            "Number of Epoch = 5 - Categorical Cross-Entropy:= 0.17022198332457983\n",
            "Number of Epoch = 5 - Accuracy:= 0.570252234194459\n",
            "Number of Epoch = 6 - Categorical Cross-Entropy:= 0.15364607405462186\n",
            "Number of Epoch = 6 - Accuracy:= 0.5889914632845326\n",
            "Number of Epoch = 7 - Categorical Cross-Entropy:= 0.1418840762867647\n",
            "Number of Epoch = 7 - Accuracy:= 0.6093281721868434\n",
            "Number of Epoch = 8 - Categorical Cross-Entropy:= 0.1343160287552521\n",
            "Number of Epoch = 8 - Accuracy:= 0.6256299443605567\n",
            "Number of Epoch = 9 - Categorical Cross-Entropy:= 0.12881384585084033\n",
            "Number of Epoch = 9 - Accuracy:= 0.6437807740283613\n",
            "Number of Epoch = 10 - Categorical Cross-Entropy:= 0.12338097426470589\n",
            "Number of Epoch = 10 - Accuracy:= 0.6678145721179096\n",
            "\n",
            "Total time taken (in seconds): 754.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot"
      ],
      "metadata": {
        "id": "mPAivQvEjGUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = [0.4708428390887605,0.5183211126247373,0.5553782743566177,0.5611766654904149,0.570252234194459,0.5889914632845326,0.6093281721868434,0.6256299443605567,0.6437807740283613,0.6678145721179096]"
      ],
      "metadata": {
        "id": "BgZuE_7WjR2p"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = [0.30573,0.25576,0.21250,0.18682,0.17022,0.15364,0.14188,0.13431,0.12881,0.12338]"
      ],
      "metadata": {
        "id": "kdSbbaXsj3eY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Train Accuracy')\n",
        "plt.title('MNIST-784 dataset')\n",
        "plt.plot(acc)\n",
        "plt.plot(acc)\n",
        "# plt.plot(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "B3fd_vJ8jF7W",
        "outputId": "084d9ea3-20d1-405e-f2d5-d98f53f481c4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f98af869950>]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Train Loss')\n",
        "plt.title('MNIST-784 dataset')\n",
        "plt.plot(loss)\n",
        "plt.plot(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "BDq4qpBfj2E7",
        "outputId": "af01d8ed-f437-4da2-a7f9-7e12f79d9ccc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f98af7a38d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case 6\n",
        "\n",
        "In this case, the implementation is done by adding regularizing function by applying a combination of l1 and l2 penalty/regularization which is called Elastic Net Regularization."
      ],
      "metadata": {
        "id": "gWYl-DUAh3fX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into batches\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(16)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(4)"
      ],
      "metadata": {
        "id": "PytDFCuhiDh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden, self.size_output, self.dropout_layer, self.device =\\\n",
        "    size_input, size_hidden, size_output, tf.keras.layers.Dropout(rate=0.2), device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer-1\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden[0]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden[0]]))\n",
        "\n",
        "    # Initialize weights between hidden layer-1 and hidden layer-2\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden[0], self.size_hidden[1]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden[1]]))\n",
        "\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden[1], self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
        "    \n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.keras.losses.CategoricalCrossentropy()(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      L1= (tf.reduce_sum(self.W1)+ tf.reduce_sum(self.W2)+tf.reduce_sum(self.W3)) # L1 = absolute sum of weights (Also known as Lasso)\n",
        "      L2= (tf.reduce_sum(tf.square(self.W1))+ tf.reduce_sum(tf.square(self.W2))+tf.reduce_sum(tf.square(self.W3)))/3 # L2 = (absolute sum of squared weights)/no.of weights (Also known as Lasso)\n",
        "      current_loss = self.loss(predicted, y_train) + 0.02*L1 + 0.03 * L2 # Lambda/Regularization Parameter for L1 = 0.02, Lambda/Regularization Parameter for L2 = 0.03\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    # Compute values in hidden layer1\n",
        "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat1 = tf.nn.relu(what1)\n",
        "    # hhat1 = self.dropout_layer(hhat1)\n",
        "    # Compute values in hidden layer2\n",
        "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    hhat2 = tf.nn.relu(what2)\n",
        "    # hhat2 = self.dropout_layer(hhat2)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat2, self.W3) + self.b3\n",
        "    #output = tf.keras.activations.softmax(output)\n",
        "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
        "    #Second add tf.Softmax(output) and then return this variable\n",
        "    return output"
      ],
      "metadata": {
        "id": "5C6OTwajprZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10"
      ],
      "metadata": {
        "id": "5F2URu9Qprmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Default mode\n",
        "mlp_on_default = MLP(size_input, size_hidden, size_output)\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_a = tf.zeros([], dtype=tf.float32)\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(25, seed=epoch*(5997)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_default.forward(inputs)\n",
        "    pred = preds  # Applying softmax to logits to get better accuracy\n",
        "\n",
        "\n",
        "    outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "    pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "\n",
        "\n",
        "    accuracy_a = accuracy_a + accuracy\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_default.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_default.loss(preds, outputs)\n",
        "    mlp_on_default.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Categorical Cross-Entropy:= {}'.format(epoch + 1, np.sum(loss_total_gpu) / x_train.shape[0]))\n",
        "  print('Number of Epoch = {} - Accuracy:= {}'.format(epoch + 1, (np.sum(accuracy_a) / x_train.shape[0])*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbFz4lSuprv-",
        "outputId": "972cdb16-38e8-42fd-d8d3-103546310909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Categorical Cross-Entropy:= 0.0465773043592437\n",
            "Number of Epoch = 1 - Accuracy:= 0.7179524397649685\n",
            "Number of Epoch = 2 - Categorical Cross-Entropy:= 0.04533393513655462\n",
            "Number of Epoch = 2 - Accuracy:= 0.721107995810629\n",
            "Number of Epoch = 3 - Categorical Cross-Entropy:= 0.04525269580488445\n",
            "Number of Epoch = 3 - Accuracy:= 0.7275282915900736\n",
            "Number of Epoch = 4 - Categorical Cross-Entropy:= 0.04549684053308824\n",
            "Number of Epoch = 4 - Accuracy:= 0.7347594189042805\n",
            "Number of Epoch = 5 - Categorical Cross-Entropy:= 0.04522398158482143\n",
            "Number of Epoch = 5 - Accuracy:= 0.7332487346745339\n",
            "Number of Epoch = 6 - Categorical Cross-Entropy:= 0.04505252100840336\n",
            "Number of Epoch = 6 - Accuracy:= 0.7236176178234965\n",
            "Number of Epoch = 7 - Categorical Cross-Entropy:= 0.04486672383797269\n",
            "Number of Epoch = 7 - Accuracy:= 0.7244403101816899\n",
            "Number of Epoch = 8 - Categorical Cross-Entropy:= 0.04469534122242647\n",
            "Number of Epoch = 8 - Accuracy:= 0.7296332992425485\n",
            "Number of Epoch = 9 - Categorical Cross-Entropy:= 0.04440693933823529\n",
            "Number of Epoch = 9 - Accuracy:= 0.7301447251263787\n",
            "Number of Epoch = 10 - Categorical Cross-Entropy:= 0.0433485876772584\n",
            "Number of Epoch = 10 - Accuracy:= 0.7365259763573399\n",
            "\n",
            "Total time taken (in seconds): 99.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "accuracy_a = tf.zeros([], dtype=tf.float32)\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_default.forward(inputs)\n",
        "\n",
        "  pred = preds\n",
        "  outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "  pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "  correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  accuracy_a = accuracy_a + accuracy\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_default.loss(preds, outputs)\n",
        "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
        "# print(X_train.shape[0])\n",
        "# print(test_loss_total.numpy())\n",
        "# print(b)\n",
        "print('Test Categorical_Cross-Entropy: {:.4f}'.format(np.sum(test_loss_total.numpy()) / x_train.shape[0]))\n",
        "print('Test Accuracy: {:.4f}'.format((np.sum(accuracy_a) / x_train.shape[0])*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yX2Q_SSe4o-a",
        "outputId": "64582864-843c-425e-bbb6-59ec91c4c6f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Categorical_Cross-Entropy: 0.0459\n",
            "Test Accuracy: 0.7068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot"
      ],
      "metadata": {
        "id": "0O7iBimikv96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = [0.71795,0.72110,0.72752,0.73475,0.73324,0.73361,0.73444,0.73363,0.73014,0.73652]"
      ],
      "metadata": {
        "id": "CpxJZ-skkxXI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = [0.0465,0.0453,0.0452,0.0454,0.0452,0.0450,0.0448,0.0446,0.0444,0.0433]"
      ],
      "metadata": {
        "id": "jLPdemaGkxSq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Train Accuracy')\n",
        "plt.title('MNIST-784 dataset')\n",
        "plt.plot(acc)\n",
        "plt.plot(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "03ef322a-e18a-458e-c7fb-9ad69948cf8b",
        "id": "k7CMVZwykvWC"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f98af708710>]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Train Loss')\n",
        "plt.title('MNIST-784 dataset')\n",
        "plt.plot(loss)\n",
        "plt.plot(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "43404fb9-98a2-4b26-c056-da28daf67303",
        "id": "YCBgocyukvWD"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f98af679110>]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case 7\n",
        "\n",
        "Hyper Parameter Optimization for Batch Size using Trial and Error\n"
      ],
      "metadata": {
        "id": "cT-CU3DB0Tpf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch Size = 20 (default)"
      ],
      "metadata": {
        "id": "xZc82kzD-GGV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY_U6JFeFYHB"
      },
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_hidden, size_output, device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer-1\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden[0]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden[0]]))\n",
        "\n",
        "    # Initialize weights between hidden layer-1 and hidden layer-2\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden[0], self.size_hidden[1]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden[1]]))\n",
        "\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden[1], self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
        "    \n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.keras.losses.CategoricalCrossentropy()(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    # Compute values in hidden layer1\n",
        "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat1 = tf.nn.relu(what1)\n",
        "    # Compute values in hidden layer2\n",
        "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    hhat2 = tf.nn.relu(what2)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat2, self.W3) + self.b3\n",
        "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
        "    #Second add tf.Softmax(output) and then return this variable\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a59c4792-70fb-4598-db09-6b073824c006",
        "id": "W4AXZbzAFYHK"
      },
      "source": [
        "#Default mode\n",
        "mlp_on_default = MLP(size_input, size_hidden, size_output)\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_a = tf.zeros([], dtype=tf.float32) #tensor for accumulating accuracy\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(25, seed=epoch*(5997)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_default.forward(inputs)\n",
        "    pred = tf.nn.softmax(preds)\n",
        "\n",
        "\n",
        "    outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "    pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "\n",
        "\n",
        "    accuracy_a = accuracy_a + accuracy\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_default.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_default.loss(preds, outputs)\n",
        "    mlp_on_default.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Categorical Cross-Entropy:= {}'.format(epoch + 1, np.sum(loss_total_gpu) / x_train.shape[0]))\n",
        "  print('Number of Epoch = {} - Accuracy:= {}'.format(epoch + 1, (np.sum(accuracy_a) / x_train.shape[0])*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Categorical Cross-Entropy:= 0.30573391544117645\n",
            "Number of Epoch = 1 - Accuracy:= 0.4708428390887605\n",
            "Number of Epoch = 2 - Categorical Cross-Entropy:= 0.25576692161239495\n",
            "Number of Epoch = 2 - Accuracy:= 0.5183211126247373\n",
            "Number of Epoch = 3 - Categorical Cross-Entropy:= 0.2125008862920168\n",
            "Number of Epoch = 3 - Accuracy:= 0.5553782743566177\n",
            "Number of Epoch = 4 - Categorical Cross-Entropy:= 0.18682595850840336\n",
            "Number of Epoch = 4 - Accuracy:= 0.5611766654904149\n",
            "Number of Epoch = 5 - Categorical Cross-Entropy:= 0.17022198332457983\n",
            "Number of Epoch = 5 - Accuracy:= 0.570252234194459\n",
            "Number of Epoch = 6 - Categorical Cross-Entropy:= 0.15364607405462186\n",
            "Number of Epoch = 6 - Accuracy:= 0.5889914632845326\n",
            "Number of Epoch = 7 - Categorical Cross-Entropy:= 0.1418840762867647\n",
            "Number of Epoch = 7 - Accuracy:= 0.6093281721868434\n",
            "Number of Epoch = 8 - Categorical Cross-Entropy:= 0.1343160287552521\n",
            "Number of Epoch = 8 - Accuracy:= 0.6256299443605567\n",
            "Number of Epoch = 9 - Categorical Cross-Entropy:= 0.12881384585084033\n",
            "Number of Epoch = 9 - Accuracy:= 0.6437807740283613\n",
            "Number of Epoch = 10 - Categorical Cross-Entropy:= 0.12338097426470589\n",
            "Number of Epoch = 10 - Accuracy:= 0.6678145721179096\n",
            "\n",
            "Total time taken (in seconds): 754.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "accuracy_a = tf.zeros([], dtype=tf.float32)\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_default.forward(inputs)\n",
        "\n",
        "  pred = tf.nn.softmax(preds)  # Apply softmax to logits\n",
        "  outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "  pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "  correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  accuracy_a = accuracy_a + accuracy\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_default.loss(preds, outputs)\n",
        "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
        "# print(X_train.shape[0])\n",
        "# print(test_loss_total.numpy())\n",
        "# print(b)\n",
        "print('Test Categorical_Cross-Entropy: {:.4f}'.format(np.sum(test_loss_total.numpy()) / x_train.shape[0]))\n",
        "print('Test Accuracy: {:.4f}'.format((np.sum(accuracy_a) / x_train.shape[0])*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb16a39c-00bd-43f7-d370-29e1440a99b9",
        "id": "pcMefsXlFYHK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Categorical_Cross-Entropy: 0.1070\n",
            "Test Accuracy: 0.5895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch Size = 256"
      ],
      "metadata": {
        "id": "Nzbfp7U2-8p6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVC9BWt_Fqfk"
      },
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_hidden, size_output, device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer-1\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden[0]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden[0]]))\n",
        "\n",
        "    # Initialize weights between hidden layer-1 and hidden layer-2\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden[0], self.size_hidden[1]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden[1]]))\n",
        "\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden[1], self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
        "    \n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.keras.losses.CategoricalCrossentropy()(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    # Compute values in hidden layer1\n",
        "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat1 = tf.nn.relu(what1)\n",
        "    # Compute values in hidden layer2\n",
        "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    hhat2 = tf.nn.relu(what2)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat2, self.W3) + self.b3\n",
        "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
        "    #Second add tf.Softmax(output) and then return this variable\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6a49e69-a313-432b-ec94-8d3722ad8f26",
        "id": "7YeVvxetFqfl"
      },
      "source": [
        "#Default mode\n",
        "mlp_on_default = MLP(size_input, size_hidden, size_output)\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_a = tf.zeros([], dtype=tf.float32) #tensor for accumulating accuracy\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(25, seed=epoch*(5997)).batch(256)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_default.forward(inputs)\n",
        "    pred = tf.nn.softmax(preds)\n",
        "\n",
        "\n",
        "    outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "    pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "\n",
        "\n",
        "    accuracy_a = accuracy_a + accuracy\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_default.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_default.loss(preds, outputs)\n",
        "    mlp_on_default.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Categorical Cross-Entropy:= {}'.format(epoch + 1, np.sum(loss_total_gpu) / x_train.shape[0]))\n",
        "  print('Number of Epoch = {} - Accuracy:= {}'.format(epoch + 1, (np.sum(accuracy_a) / x_train.shape[0])*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Categorical Cross-Entropy:= 0.029556712431066178\n",
            "Number of Epoch = 1 - Accuracy:= 0.04359851484539128\n",
            "Number of Epoch = 2 - Categorical Cross-Entropy:= 0.029474002100840335\n",
            "Number of Epoch = 2 - Accuracy:= 0.043638636484867384\n",
            "Number of Epoch = 3 - Categorical Cross-Entropy:= 0.029408348788734245\n",
            "Number of Epoch = 3 - Accuracy:= 0.04367972942961364\n",
            "Number of Epoch = 4 - Categorical Cross-Entropy:= 0.02934698127297794\n",
            "Number of Epoch = 4 - Accuracy:= 0.043690426610097165\n",
            "Number of Epoch = 5 - Categorical Cross-Entropy:= 0.02930344012605042\n",
            "Number of Epoch = 5 - Accuracy:= 0.043712555059865744\n",
            "Number of Epoch = 6 - Categorical Cross-Entropy:= 0.029254142184217437\n",
            "Number of Epoch = 6 - Accuracy:= 0.043701854673754266\n",
            "Number of Epoch = 7 - Categorical Cross-Entropy:= 0.02919454725249475\n",
            "Number of Epoch = 7 - Accuracy:= 0.043716687114298845\n",
            "Number of Epoch = 8 - Categorical Cross-Entropy:= 0.029116766921612396\n",
            "Number of Epoch = 8 - Accuracy:= 0.043716687114298845\n",
            "Number of Epoch = 9 - Categorical Cross-Entropy:= 0.029056341091123948\n",
            "Number of Epoch = 9 - Accuracy:= 0.043696991736147585\n",
            "Number of Epoch = 10 - Categorical Cross-Entropy:= 0.029008311039259455\n",
            "Number of Epoch = 10 - Accuracy:= 0.043714984925855106\n",
            "\n",
            "Total time taken (in seconds): 53.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "accuracy_a = tf.zeros([], dtype=tf.float32)\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_default.forward(inputs)\n",
        "\n",
        "  pred = tf.nn.softmax(preds)  # Apply softmax to logits\n",
        "  outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "  pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "  correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  accuracy_a = accuracy_a + accuracy\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_default.loss(preds, outputs)\n",
        "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
        "# print(X_train.shape[0])\n",
        "# print(test_loss_total.numpy())\n",
        "# print(b)\n",
        "print('Test Categorical_Cross-Entropy: {:.4f}'.format(np.sum(test_loss_total.numpy()) / x_train.shape[0]))\n",
        "print('Test Accuracy: {:.4f}'.format((np.sum(accuracy_a) / x_train.shape[0])*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e2dedcb-3ca7-4231-9d2b-c014c9e01284",
        "id": "tpj2WW7dFqfm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Categorical_Cross-Entropy: 0.3290\n",
            "Test Accuracy: 0.5038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CVofaVi80hML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case 8\n",
        "\n",
        "Hyper Parameter Optimization for Optimizers - AdaM instead of SGD using Trial and Error"
      ],
      "metadata": {
        "id": "LborlVe00-qk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SGD"
      ],
      "metadata": {
        "id": "htFa83I7ILbm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFZvDkAVIUOi"
      },
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_hidden, size_output, device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer-1\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden[0]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden[0]]))\n",
        "\n",
        "    # Initialize weights between hidden layer-1 and hidden layer-2\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden[0], self.size_hidden[1]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden[1]]))\n",
        "\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden[1], self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
        "    \n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.keras.losses.CategoricalCrossentropy()(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    # Compute values in hidden layer1\n",
        "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat1 = tf.nn.relu(what1)\n",
        "    # Compute values in hidden layer2\n",
        "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    hhat2 = tf.nn.relu(what2)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat2, self.W3) + self.b3\n",
        "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
        "    #Second add tf.Softmax(output) and then return this variable\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a59c4792-70fb-4598-db09-6b073824c006",
        "id": "8v8ukk9RIUOk"
      },
      "source": [
        "#Default mode\n",
        "mlp_on_default = MLP(size_input, size_hidden, size_output)\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_a = tf.zeros([], dtype=tf.float32) #tensor for accumulating accuracy\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(25, seed=epoch*(5997)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_default.forward(inputs)\n",
        "    pred = tf.nn.softmax(preds)\n",
        "\n",
        "\n",
        "    outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "    pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "\n",
        "\n",
        "    accuracy_a = accuracy_a + accuracy\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_default.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_default.loss(preds, outputs)\n",
        "    mlp_on_default.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Categorical Cross-Entropy:= {}'.format(epoch + 1, np.sum(loss_total_gpu) / x_train.shape[0]))\n",
        "  print('Number of Epoch = {} - Accuracy:= {}'.format(epoch + 1, (np.sum(accuracy_a) / x_train.shape[0])*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Categorical Cross-Entropy:= 0.30573391544117645\n",
            "Number of Epoch = 1 - Accuracy:= 0.4708428390887605\n",
            "Number of Epoch = 2 - Categorical Cross-Entropy:= 0.25576692161239495\n",
            "Number of Epoch = 2 - Accuracy:= 0.5183211126247373\n",
            "Number of Epoch = 3 - Categorical Cross-Entropy:= 0.2125008862920168\n",
            "Number of Epoch = 3 - Accuracy:= 0.5553782743566177\n",
            "Number of Epoch = 4 - Categorical Cross-Entropy:= 0.18682595850840336\n",
            "Number of Epoch = 4 - Accuracy:= 0.5611766654904149\n",
            "Number of Epoch = 5 - Categorical Cross-Entropy:= 0.17022198332457983\n",
            "Number of Epoch = 5 - Accuracy:= 0.570252234194459\n",
            "Number of Epoch = 6 - Categorical Cross-Entropy:= 0.15364607405462186\n",
            "Number of Epoch = 6 - Accuracy:= 0.5889914632845326\n",
            "Number of Epoch = 7 - Categorical Cross-Entropy:= 0.1418840762867647\n",
            "Number of Epoch = 7 - Accuracy:= 0.6093281721868434\n",
            "Number of Epoch = 8 - Categorical Cross-Entropy:= 0.1343160287552521\n",
            "Number of Epoch = 8 - Accuracy:= 0.6256299443605567\n",
            "Number of Epoch = 9 - Categorical Cross-Entropy:= 0.12881384585084033\n",
            "Number of Epoch = 9 - Accuracy:= 0.6437807740283613\n",
            "Number of Epoch = 10 - Categorical Cross-Entropy:= 0.12338097426470589\n",
            "Number of Epoch = 10 - Accuracy:= 0.6678145721179096\n",
            "\n",
            "Total time taken (in seconds): 754.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "accuracy_a = tf.zeros([], dtype=tf.float32)\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_default.forward(inputs)\n",
        "\n",
        "  pred = tf.nn.softmax(preds)  # Apply softmax to logits\n",
        "  outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "  pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "  correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  accuracy_a = accuracy_a + accuracy\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_default.loss(preds, outputs)\n",
        "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
        "# print(X_train.shape[0])\n",
        "# print(test_loss_total.numpy())\n",
        "# print(b)\n",
        "print('Test Categorical_Cross-Entropy: {:.4f}'.format(np.sum(test_loss_total.numpy()) / x_train.shape[0]))\n",
        "print('Test Accuracy: {:.4f}'.format((np.sum(accuracy_a) / x_train.shape[0])*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb16a39c-00bd-43f7-d370-29e1440a99b9",
        "id": "NBPs7E1GIUOk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Categorical_Cross-Entropy: 0.1070\n",
            "Test Accuracy: 0.5895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adam"
      ],
      "metadata": {
        "id": "eWZw4_KOIZMq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5RWOrdvIayW"
      },
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_hidden, size_output, device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer-1\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden[0]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden[0]]))\n",
        "\n",
        "    # Initialize weights between hidden layer-1 and hidden layer-2\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden[0], self.size_hidden[1]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden[1]]))\n",
        "\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden[1], self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
        "    \n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.keras.losses.CategoricalCrossentropy()(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    # Compute values in hidden layer1\n",
        "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat1 = tf.nn.relu(what1)\n",
        "    # Compute values in hidden layer2\n",
        "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    hhat2 = tf.nn.relu(what2)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat2, self.W3) + self.b3\n",
        "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
        "    #Second add tf.Softmax(output) and then return this variable\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25a4a6f3-290f-4224-dfce-3fd9f26055fe",
        "id": "kYDIepUFIayc"
      },
      "source": [
        "#Default mode\n",
        "mlp_on_default = MLP(size_input, size_hidden, size_output)\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_a = tf.zeros([], dtype=tf.float32) #tensor for accumulating accuracy\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(25, seed=epoch*(5997)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_default.forward(inputs)\n",
        "    pred = preds\n",
        "\n",
        "\n",
        "    outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "    pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "\n",
        "\n",
        "    accuracy_a = accuracy_a + accuracy\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_default.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_default.loss(preds, outputs)\n",
        "    mlp_on_default.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Categorical Cross-Entropy:= {}'.format(epoch + 1, np.sum(loss_total_gpu) / x_train.shape[0]))\n",
        "  print('Number of Epoch = {} - Accuracy:= {}'.format(epoch + 1, (np.sum(accuracy_a) / x_train.shape[0])*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Categorical Cross-Entropy:= 0.028099601168592437\n",
            "Number of Epoch = 1 - Accuracy:= 0.6108154168649882\n",
            "Number of Epoch = 2 - Categorical Cross-Entropy:= 0.031094342912946427\n",
            "Number of Epoch = 2 - Accuracy:= 0.6780083279649751\n",
            "Number of Epoch = 3 - Categorical Cross-Entropy:= 0.030274124786633404\n",
            "Number of Epoch = 3 - Accuracy:= 0.6624133326426274\n",
            "Number of Epoch = 4 - Categorical Cross-Entropy:= 0.02807934980632878\n",
            "Number of Epoch = 4 - Accuracy:= 0.6390323799197414\n",
            "Number of Epoch = 5 - Categorical Cross-Entropy:= 0.026592871914390755\n",
            "Number of Epoch = 5 - Accuracy:= 0.6783629986418396\n",
            "Number of Epoch = 6 - Categorical Cross-Entropy:= 0.02693370658810399\n",
            "Number of Epoch = 6 - Accuracy:= 0.7723327123818278\n",
            "Number of Epoch = 7 - Categorical Cross-Entropy:= 0.02939727834493172\n",
            "Number of Epoch = 7 - Accuracy:= 0.8076380240817029\n",
            "Number of Epoch = 8 - Categorical Cross-Entropy:= 0.030392910484506302\n",
            "Number of Epoch = 8 - Accuracy:= 0.8262172666918329\n",
            "Number of Epoch = 9 - Categorical Cross-Entropy:= 0.030839400603991596\n",
            "Number of Epoch = 9 - Accuracy:= 0.8470026865726759\n",
            "Number of Epoch = 10 - Categorical Cross-Entropy:= 0.03093117696297269\n",
            "Number of Epoch = 10 - Accuracy:= 0.8459735517742254\n",
            "\n",
            "Total time taken (in seconds): 178.70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "accuracy_a = tf.zeros([], dtype=tf.float32)\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_default.forward(inputs)\n",
        "\n",
        "  pred = tf.nn.softmax(preds)  # Apply softmax to logits\n",
        "  outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "  pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "  correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  accuracy_a = accuracy_a + accuracy\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_default.loss(preds, outputs)\n",
        "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
        "# print(X_train.shape[0])\n",
        "# print(test_loss_total.numpy())\n",
        "# print(b)\n",
        "print('Test Categorical_Cross-Entropy: {:.4f}'.format(np.sum(test_loss_total.numpy()) / x_train.shape[0]))\n",
        "print('Test Accuracy: {:.4f}'.format((np.sum(accuracy_a) / x_train.shape[0])*100))"
      ],
      "metadata": {
        "id": "qKE-y4jiIayd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case 9\n",
        "\n",
        "Hyper Parameter Optimization for Learning Rate using Trial and Error"
      ],
      "metadata": {
        "id": "tDKfi1a8K08I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1e-4\n",
        "\n"
      ],
      "metadata": {
        "id": "HJYMHvAmJNSl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1wypke1JcAR"
      },
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_hidden, size_output, device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer-1\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden[0]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden[0]]))\n",
        "\n",
        "    # Initialize weights between hidden layer-1 and hidden layer-2\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden[0], self.size_hidden[1]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden[1]]))\n",
        "\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden[1], self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
        "    \n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.keras.losses.CategoricalCrossentropy()(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    # Compute values in hidden layer1\n",
        "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat1 = tf.nn.relu(what1)\n",
        "    # Compute values in hidden layer2\n",
        "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    hhat2 = tf.nn.relu(what2)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat2, self.W3) + self.b3\n",
        "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
        "    #Second add tf.Softmax(output) and then return this variable\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a59c4792-70fb-4598-db09-6b073824c006",
        "id": "fmt_W3VRJcAS"
      },
      "source": [
        "#Default mode\n",
        "mlp_on_default = MLP(size_input, size_hidden, size_output)\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_a = tf.zeros([], dtype=tf.float32) #tensor for accumulating accuracy\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(25, seed=epoch*(5997)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_default.forward(inputs)\n",
        "    pred = tf.nn.softmax(preds)\n",
        "\n",
        "\n",
        "    outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "    pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "\n",
        "\n",
        "    accuracy_a = accuracy_a + accuracy\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_default.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_default.loss(preds, outputs)\n",
        "    mlp_on_default.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Categorical Cross-Entropy:= {}'.format(epoch + 1, np.sum(loss_total_gpu) / x_train.shape[0]))\n",
        "  print('Number of Epoch = {} - Accuracy:= {}'.format(epoch + 1, (np.sum(accuracy_a) / x_train.shape[0])*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Categorical Cross-Entropy:= 0.30573391544117645\n",
            "Number of Epoch = 1 - Accuracy:= 0.4708428390887605\n",
            "Number of Epoch = 2 - Categorical Cross-Entropy:= 0.25576692161239495\n",
            "Number of Epoch = 2 - Accuracy:= 0.5183211126247373\n",
            "Number of Epoch = 3 - Categorical Cross-Entropy:= 0.2125008862920168\n",
            "Number of Epoch = 3 - Accuracy:= 0.5553782743566177\n",
            "Number of Epoch = 4 - Categorical Cross-Entropy:= 0.18682595850840336\n",
            "Number of Epoch = 4 - Accuracy:= 0.5611766654904149\n",
            "Number of Epoch = 5 - Categorical Cross-Entropy:= 0.17022198332457983\n",
            "Number of Epoch = 5 - Accuracy:= 0.570252234194459\n",
            "Number of Epoch = 6 - Categorical Cross-Entropy:= 0.15364607405462186\n",
            "Number of Epoch = 6 - Accuracy:= 0.5889914632845326\n",
            "Number of Epoch = 7 - Categorical Cross-Entropy:= 0.1418840762867647\n",
            "Number of Epoch = 7 - Accuracy:= 0.6093281721868434\n",
            "Number of Epoch = 8 - Categorical Cross-Entropy:= 0.1343160287552521\n",
            "Number of Epoch = 8 - Accuracy:= 0.6256299443605567\n",
            "Number of Epoch = 9 - Categorical Cross-Entropy:= 0.12881384585084033\n",
            "Number of Epoch = 9 - Accuracy:= 0.6437807740283613\n",
            "Number of Epoch = 10 - Categorical Cross-Entropy:= 0.12338097426470589\n",
            "Number of Epoch = 10 - Accuracy:= 0.6678145721179096\n",
            "\n",
            "Total time taken (in seconds): 754.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "accuracy_a = tf.zeros([], dtype=tf.float32)\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_default.forward(inputs)\n",
        "\n",
        "  pred = tf.nn.softmax(preds)  # Apply softmax to logits\n",
        "  outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "  pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "  correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  accuracy_a = accuracy_a + accuracy\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_default.loss(preds, outputs)\n",
        "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
        "# print(X_train.shape[0])\n",
        "# print(test_loss_total.numpy())\n",
        "# print(b)\n",
        "print('Test Categorical_Cross-Entropy: {:.4f}'.format(np.sum(test_loss_total.numpy()) / x_train.shape[0]))\n",
        "print('Test Accuracy: {:.4f}'.format((np.sum(accuracy_a) / x_train.shape[0])*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb16a39c-00bd-43f7-d370-29e1440a99b9",
        "id": "gIB2hliHJcAT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Categorical_Cross-Entropy: 0.1070\n",
            "Test Accuracy: 0.5895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1e-3"
      ],
      "metadata": {
        "id": "f8eINVIRJdC5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYeSOTiBJhWg"
      },
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_hidden, size_output, device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer-1\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden[0]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden[0]]))\n",
        "\n",
        "    # Initialize weights between hidden layer-1 and hidden layer-2\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden[0], self.size_hidden[1]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden[1]]))\n",
        "\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden[1], self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
        "    \n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.keras.losses.CategoricalCrossentropy()(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    # Compute values in hidden layer1\n",
        "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat1 = tf.nn.relu(what1)\n",
        "    # Compute values in hidden layer2\n",
        "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    hhat2 = tf.nn.relu(what2)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat2, self.W3) + self.b3\n",
        "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
        "    #Second add tf.Softmax(output) and then return this variable\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be96060-10b3-4002-f57c-de45e0457968",
        "id": "IkQjbfQ6JhWh"
      },
      "source": [
        "#Default mode\n",
        "mlp_on_default = MLP(size_input, size_hidden, size_output)\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_a = tf.zeros([], dtype=tf.float32) #tensor for accumulating accuracy\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(25, seed=epoch*(5997)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_default.forward(inputs)\n",
        "    pred = tf.nn.softmax(preds)\n",
        "\n",
        "\n",
        "    outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "    pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "\n",
        "\n",
        "    accuracy_a = accuracy_a + accuracy\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_default.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_default.loss(preds, outputs)\n",
        "    mlp_on_default.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Categorical Cross-Entropy:= {}'.format(epoch + 1, np.sum(loss_total_gpu) / x_train.shape[0]))\n",
        "  print('Number of Epoch = {} - Accuracy:= {}'.format(epoch + 1, (np.sum(accuracy_a) / x_train.shape[0])*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Categorical Cross-Entropy:= 0.3356025800945378\n",
            "Number of Epoch = 1 - Accuracy:= 0.5032789727219013\n",
            "Number of Epoch = 2 - Categorical Cross-Entropy:= 0.22050091911764705\n",
            "Number of Epoch = 2 - Accuracy:= 0.5159667455849527\n",
            "Number of Epoch = 3 - Categorical Cross-Entropy:= 0.2503140263918067\n",
            "Number of Epoch = 3 - Accuracy:= 0.5105902663799895\n",
            "Number of Epoch = 4 - Categorical Cross-Entropy:= 0.35725544905462187\n",
            "Number of Epoch = 4 - Accuracy:= 0.4324413139279149\n",
            "Number of Epoch = 5 - Categorical Cross-Entropy:= 0.24452031906512606\n",
            "Number of Epoch = 5 - Accuracy:= 0.3936176716780462\n",
            "Number of Epoch = 6 - Categorical Cross-Entropy:= 0.23529111410189077\n",
            "Number of Epoch = 6 - Accuracy:= 0.41151674414883144\n",
            "Number of Epoch = 7 - Categorical Cross-Entropy:= 0.22938906578256302\n",
            "Number of Epoch = 7 - Accuracy:= 0.44395295471704305\n",
            "Number of Epoch = 8 - Categorical Cross-Entropy:= 0.2231200105042017\n",
            "Number of Epoch = 8 - Accuracy:= 0.4885735519793855\n",
            "Number of Epoch = 9 - Categorical Cross-Entropy:= 0.22131707917542018\n",
            "Number of Epoch = 9 - Accuracy:= 0.4988259708180147\n",
            "Number of Epoch = 10 - Categorical Cross-Entropy:= 0.26223990611869746\n",
            "Number of Epoch = 10 - Accuracy:= 0.5018508013556985\n",
            "\n",
            "Total time taken (in seconds): 598.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "accuracy_a = tf.zeros([], dtype=tf.float32)\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_default.forward(inputs)\n",
        "\n",
        "  pred = tf.nn.softmax(preds)  # Apply softmax to logits\n",
        "  outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "  pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "  correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  accuracy_a = accuracy_a + accuracy\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_default.loss(preds, outputs)\n",
        "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
        "# print(X_train.shape[0])\n",
        "# print(test_loss_total.numpy())\n",
        "# print(b)\n",
        "print('Test Categorical_Cross-Entropy: {:.4f}'.format(np.sum(test_loss_total.numpy()) / x_train.shape[0]))\n",
        "print('Test Accuracy: {:.4f}'.format((np.sum(accuracy_a) / x_train.shape[0])*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30fb9dc7-feb1-4da1-c240-5f7534bc1dae",
        "id": "KnbENMDqJhWi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Categorical_Cross-Entropy: 0.3661\n",
            "Test Accuracy: 0.4277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ie-5"
      ],
      "metadata": {
        "id": "bW-3BJcIMFN9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WTwo5q_MHso"
      },
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_hidden, size_output, device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer-1\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden[0]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden[0]]))\n",
        "\n",
        "    # Initialize weights between hidden layer-1 and hidden layer-2\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden[0], self.size_hidden[1]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden[1]]))\n",
        "\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden[1], self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
        "    \n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.keras.losses.CategoricalCrossentropy()(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-5)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    # Compute values in hidden layer1\n",
        "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat1 = tf.nn.relu(what1)\n",
        "    # Compute values in hidden layer2\n",
        "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    hhat2 = tf.nn.relu(what2)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat2, self.W3) + self.b3\n",
        "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
        "    #Second add tf.Softmax(output) and then return this variable\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a143b185-f46f-4ea4-def7-8beb29809748",
        "id": "6ZSuWdWyMHsp"
      },
      "source": [
        "#Default mode\n",
        "mlp_on_default = MLP(size_input, size_hidden, size_output)\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_a = tf.zeros([], dtype=tf.float32) #tensor for accumulating accuracy\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(25, seed=epoch*(5997)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_default.forward(inputs)\n",
        "    pred = tf.nn.softmax(preds)\n",
        "\n",
        "\n",
        "    outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "    pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "\n",
        "\n",
        "    accuracy_a = accuracy_a + accuracy\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_default.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_default.loss(preds, outputs)\n",
        "    mlp_on_default.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Categorical Cross-Entropy:= {}'.format(epoch + 1, np.sum(loss_total_gpu) / x_train.shape[0]))\n",
        "  print('Number of Epoch = {} - Accuracy:= {}'.format(epoch + 1, (np.sum(accuracy_a) / x_train.shape[0])*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Categorical Cross-Entropy:= 0.32479851628151263\n",
            "Number of Epoch = 1 - Accuracy:= 0.4610115115382091\n",
            "Number of Epoch = 2 - Categorical Cross-Entropy:= 0.31970000656512604\n",
            "Number of Epoch = 2 - Accuracy:= 0.4584896824940914\n",
            "Number of Epoch = 3 - Categorical Cross-Entropy:= 0.3176233915441177\n",
            "Number of Epoch = 3 - Accuracy:= 0.4598348152737658\n",
            "Number of Epoch = 4 - Categorical Cross-Entropy:= 0.31290296743697477\n",
            "Number of Epoch = 4 - Accuracy:= 0.4638682133009454\n",
            "Number of Epoch = 5 - Categorical Cross-Entropy:= 0.3082079175420168\n",
            "Number of Epoch = 5 - Accuracy:= 0.4627750172334559\n",
            "Number of Epoch = 6 - Categorical Cross-Entropy:= 0.30051037289915966\n",
            "Number of Epoch = 6 - Accuracy:= 0.46622058002888656\n",
            "Number of Epoch = 7 - Categorical Cross-Entropy:= 0.29514206932773107\n",
            "Number of Epoch = 7 - Accuracy:= 0.4667256844143907\n",
            "Number of Epoch = 8 - Categorical Cross-Entropy:= 0.2908782825630252\n",
            "Number of Epoch = 8 - Accuracy:= 0.4928585276884191\n",
            "Number of Epoch = 9 - Categorical Cross-Entropy:= 0.28804789259453784\n",
            "Number of Epoch = 9 - Accuracy:= 0.4921869870995273\n",
            "Number of Epoch = 10 - Categorical Cross-Entropy:= 0.28032993040966386\n",
            "Number of Epoch = 10 - Accuracy:= 0.4931107208508403\n",
            "\n",
            "Total time taken (in seconds): 725.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "accuracy_a = tf.zeros([], dtype=tf.float32)\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_default.forward(inputs)\n",
        "\n",
        "  pred = tf.nn.softmax(preds)  # Apply softmax to logits\n",
        "  outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "  pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "  correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  accuracy_a = accuracy_a + accuracy\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_default.loss(preds, outputs)\n",
        "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
        "# print(X_train.shape[0])\n",
        "# print(test_loss_total.numpy())\n",
        "# print(b)\n",
        "print('Test Categorical_Cross-Entropy: {:.4f}'.format(np.sum(test_loss_total.numpy()) / x_train.shape[0]))\n",
        "print('Test Accuracy: {:.4f}'.format((np.sum(accuracy_a) / x_train.shape[0])*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scjiiqh0MHsp",
        "outputId": "11ea650f-7e4c-4a85-f518-fd3665b7b808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Categorical_Cross-Entropy: 0.2415\n",
            "Test Accuracy: 0.4479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_hcD9-DXK08K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LrkWHr5HK08K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IgCD6NdQK0ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case 10\n",
        "\n",
        "Hyper Parameter Optimization for Activation Function using Trial and Error"
      ],
      "metadata": {
        "id": "SQx2SfI-0iN-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Relu"
      ],
      "metadata": {
        "id": "KlTRf3mHMY_8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRRLyDCCMfQn"
      },
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_hidden, size_output, device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer-1\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden[0]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden[0]]))\n",
        "\n",
        "    # Initialize weights between hidden layer-1 and hidden layer-2\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden[0], self.size_hidden[1]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden[1]]))\n",
        "\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden[1], self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
        "    \n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.keras.losses.CategoricalCrossentropy()(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    # Compute values in hidden layer1\n",
        "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat1 = tf.nn.relu(what1)\n",
        "    # Compute values in hidden layer2\n",
        "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    hhat2 = tf.nn.relu(what2)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat2, self.W3) + self.b3\n",
        "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
        "    #Second add tf.Softmax(output) and then return this variable\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQipc4cmMfQr"
      },
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a59c4792-70fb-4598-db09-6b073824c006",
        "id": "xC5yLRldMfQr"
      },
      "source": [
        "#Default mode\n",
        "mlp_on_default = MLP(size_input, size_hidden, size_output)\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_a = tf.zeros([], dtype=tf.float32) #tensor for accumulating accuracy\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(25, seed=epoch*(5997)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_default.forward(inputs)\n",
        "    pred = tf.nn.softmax(preds)\n",
        "\n",
        "\n",
        "    outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "    pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "\n",
        "\n",
        "    accuracy_a = accuracy_a + accuracy\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_default.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_default.loss(preds, outputs)\n",
        "    mlp_on_default.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Categorical Cross-Entropy:= {}'.format(epoch + 1, np.sum(loss_total_gpu) / x_train.shape[0]))\n",
        "  print('Number of Epoch = {} - Accuracy:= {}'.format(epoch + 1, (np.sum(accuracy_a) / x_train.shape[0])*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Categorical Cross-Entropy:= 0.30573391544117645\n",
            "Number of Epoch = 1 - Accuracy:= 0.4708428390887605\n",
            "Number of Epoch = 2 - Categorical Cross-Entropy:= 0.25576692161239495\n",
            "Number of Epoch = 2 - Accuracy:= 0.5183211126247373\n",
            "Number of Epoch = 3 - Categorical Cross-Entropy:= 0.2125008862920168\n",
            "Number of Epoch = 3 - Accuracy:= 0.5553782743566177\n",
            "Number of Epoch = 4 - Categorical Cross-Entropy:= 0.18682595850840336\n",
            "Number of Epoch = 4 - Accuracy:= 0.5611766654904149\n",
            "Number of Epoch = 5 - Categorical Cross-Entropy:= 0.17022198332457983\n",
            "Number of Epoch = 5 - Accuracy:= 0.570252234194459\n",
            "Number of Epoch = 6 - Categorical Cross-Entropy:= 0.15364607405462186\n",
            "Number of Epoch = 6 - Accuracy:= 0.5889914632845326\n",
            "Number of Epoch = 7 - Categorical Cross-Entropy:= 0.1418840762867647\n",
            "Number of Epoch = 7 - Accuracy:= 0.6093281721868434\n",
            "Number of Epoch = 8 - Categorical Cross-Entropy:= 0.1343160287552521\n",
            "Number of Epoch = 8 - Accuracy:= 0.6256299443605567\n",
            "Number of Epoch = 9 - Categorical Cross-Entropy:= 0.12881384585084033\n",
            "Number of Epoch = 9 - Accuracy:= 0.6437807740283613\n",
            "Number of Epoch = 10 - Categorical Cross-Entropy:= 0.12338097426470589\n",
            "Number of Epoch = 10 - Accuracy:= 0.6678145721179096\n",
            "\n",
            "Total time taken (in seconds): 754.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "accuracy_a = tf.zeros([], dtype=tf.float32)\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_default.forward(inputs)\n",
        "\n",
        "  pred = tf.nn.softmax(preds)  # Apply softmax to logits\n",
        "  outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "  pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "  correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  accuracy_a = accuracy_a + accuracy\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_default.loss(preds, outputs)\n",
        "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
        "# print(X_train.shape[0])\n",
        "# print(test_loss_total.numpy())\n",
        "# print(b)\n",
        "print('Test Categorical_Cross-Entropy: {:.4f}'.format(np.sum(test_loss_total.numpy()) / x_train.shape[0]))\n",
        "print('Test Accuracy: {:.4f}'.format((np.sum(accuracy_a) / x_train.shape[0])*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb16a39c-00bd-43f7-d370-29e1440a99b9",
        "id": "tJXvc4WQMfQr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Categorical_Cross-Entropy: 0.1070\n",
            "Test Accuracy: 0.5895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tanh"
      ],
      "metadata": {
        "id": "OOkkuWu3MgMx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m57BUCZNMkYR"
      },
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_hidden, size_output, device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer-1\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden[0]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden[0]]))\n",
        "\n",
        "    # Initialize weights between hidden layer-1 and hidden layer-2\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden[0], self.size_hidden[1]]))\n",
        "    # Initialize biases for hidden layer-1\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden[1]]))\n",
        "\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden[1], self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
        "    \n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.keras.losses.CategoricalCrossentropy()(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    # Compute values in hidden layer1\n",
        "    what1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat1 = tf.nn.tanh(what1)\n",
        "    # Compute values in hidden layer2\n",
        "    what2 = tf.matmul(hhat1, self.W2) + self.b2\n",
        "    hhat2 = tf.nn.tanh(what2)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat2, self.W3) + self.b3\n",
        "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
        "    #Second add tf.Softmax(output) and then return this variable\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZfQVywhMkYS"
      },
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c9e3a43-9ece-4920-f5f2-6d9e10cc8d62",
        "id": "YSBAfXzFMkYS"
      },
      "source": [
        "#Default mode\n",
        "mlp_on_default = MLP(size_input, size_hidden, size_output)\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_a = tf.zeros([], dtype=tf.float32) #tensor for accumulating accuracy\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(25, seed=epoch*(5997)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_default.forward(inputs)\n",
        "    pred = preds\n",
        "\n",
        "\n",
        "    outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "    pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "\n",
        "\n",
        "    accuracy_a = accuracy_a + accuracy\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_default.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_default.loss(preds, outputs)\n",
        "    mlp_on_default.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Categorical Cross-Entropy:= {}'.format(epoch + 1, np.sum(loss_total_gpu) / x_train.shape[0]))\n",
        "  print('Number of Epoch = {} - Accuracy:= {}'.format(epoch + 1, (np.sum(accuracy_a) / x_train.shape[0])*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Categorical Cross-Entropy:= 0.026894543559611343\n",
            "Number of Epoch = 1 - Accuracy:= 0.45227396989069063\n",
            "Number of Epoch = 2 - Categorical Cross-Entropy:= 0.026803446280856093\n",
            "Number of Epoch = 2 - Accuracy:= 0.45194571358816965\n",
            "Number of Epoch = 3 - Categorical Cross-Entropy:= 0.026746319426207983\n",
            "Number of Epoch = 3 - Accuracy:= 0.4529061517795595\n",
            "Number of Epoch = 4 - Categorical Cross-Entropy:= 0.026674517463235296\n",
            "Number of Epoch = 4 - Accuracy:= 0.45352862061572674\n",
            "Number of Epoch = 5 - Categorical Cross-Entropy:= 0.026487942735688025\n",
            "Number of Epoch = 5 - Accuracy:= 0.46576652206292674\n",
            "Number of Epoch = 6 - Categorical Cross-Entropy:= 0.025454971441701682\n",
            "Number of Epoch = 6 - Accuracy:= 0.5390406376173517\n",
            "Number of Epoch = 7 - Categorical Cross-Entropy:= 0.025367764000131302\n",
            "Number of Epoch = 7 - Accuracy:= 0.5384351586093422\n",
            "Number of Epoch = 8 - Categorical Cross-Entropy:= 0.02517694450827206\n",
            "Number of Epoch = 8 - Accuracy:= 0.5372534359202665\n",
            "Number of Epoch = 9 - Categorical Cross-Entropy:= 0.02505549583114496\n",
            "Number of Epoch = 9 - Accuracy:= 0.5393129236557904\n",
            "Number of Epoch = 10 - Categorical Cross-Entropy:= 0.024979957901129203\n",
            "Number of Epoch = 10 - Accuracy:= 0.540173698874081\n",
            "\n",
            "Total time taken (in seconds): 92.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "accuracy_a = tf.zeros([], dtype=tf.float32)\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_default.forward(inputs)\n",
        "\n",
        "  pred = tf.nn.softmax(preds)  # Apply softmax to logits\n",
        "  outputs = tf.cast(tf.reshape(outputs, (-1,10)), dtype=tf.float32)\n",
        "  pred = tf.cast(pred, dtype=tf.float32)\n",
        "\n",
        "  correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(pred, 1))\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  accuracy_a = accuracy_a + accuracy\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_default.loss(preds, outputs)\n",
        "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
        "# print(X_train.shape[0])\n",
        "# print(test_loss_total.numpy())\n",
        "# print(b)\n",
        "print('Test Categorical_Cross-Entropy: {:.4f}'.format(np.sum(test_loss_total.numpy()) / x_train.shape[0]))\n",
        "print('Test Accuracy: {:.4f}'.format((np.sum(accuracy_a) / x_train.shape[0])*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suGoIp9Yq_7i",
        "outputId": "e00c64f8-4e02-4591-a797-3b09f1ad2778"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Categorical_Cross-Entropy: 0.0240\n",
            "Test Accuracy: 0.5304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot- Bias & Varience"
      ],
      "metadata": {
        "id": "U-6OzoCIrPsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "accuracy_base = np.array([60.37, 56.23, 58.81, 55.41, 58.45, 54.99, 56.86, 61.25, 59.34, 57.56])/100.0\n",
        "mean_base = np.sum(accuracy_base)/accuracy_base.shape[0]\n",
        "standard_dev_base = np.sqrt(np.sum((accuracy_base-mean_base)**2)/(accuracy_base.shape[0]-1.0))\n",
        "standard_error_base = standard_dev_base/np.sqrt(accuracy_base.shape[0])\n",
        "variance_base = standard_dev_base**2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "accuracy_L2 = np.array([65.14, 60.81, 58.98, 59.55, 62.76, 54.91, 52.55, 60.10, 59.83, 52.74])/100.0\n",
        "mean_L1 = np.sum(accuracy_L2)/accuracy_L2.shape[0]\n",
        "standard_dev_L1 = np.sqrt(np.sum((accuracy_L2-mean_L1)**2)/(accuracy_L2.shape[0]-1.0))\n",
        "standard_error_L1 = standard_dev_L1/np.sqrt(accuracy_L2.shape[0])\n",
        "variance_L1 = standard_dev_L1**2\n",
        "\n",
        "accuracy_L1_L2 = np.array([65.21, 72.35, 67.62, 66.87, 70.47, 74.53, 69.56, 71.95, 64.33, 69.49])/100.0\n",
        "mean_L2 = np.sum(accuracy_L1_L2)/accuracy_L1_L2.shape[0]\n",
        "standard_dev_L2 = np.sqrt(np.sum((accuracy_L1_L2-mean_L2)**2)/(accuracy_L1_L2.shape[0]-1.0))\n",
        "standard_error_L2 = standard_dev_L2/np.sqrt(accuracy_L1_L2.shape[0])\n",
        "variance_L2 = standard_dev_L2**2\n",
        "\n",
        "\n",
        "x = np.array([0,1,2])\n",
        "y_mean = np.array([mean_base, mean_L1, mean_L2])\n",
        "y_standard_error = np.array([standard_error_base, standard_error_L1, standard_error_L2])\n",
        "y_variance = np.array([variance_base, variance_L1, variance_L2])\n",
        "\n",
        "plt.figure(0)\n",
        "my_xticks = ['Without Regularization','L2','L1+L2']\n",
        "plt.plot(x, y_mean, 'go', label='Mean Accuracy')\n",
        "plt.plot(x, y_standard_error, 'bo', label='Mean Standard Error')\n",
        "plt.plot(x, y_variance, 'ro', label='Mean Variance')\n",
        "plt.xticks(x, my_xticks)\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Test Score')\n",
        "plt.title('MNIST-784 dataset')\n",
        "plt.legend()\n",
        "plt.savefig('plot.jpg',dpi=200)"
      ],
      "metadata": {
        "id": "4k4fny-6L04w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f96c919e-0f93-4690-ef0f-34244eee5efc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acct = [65.14, 60.81, 58.98, 59.55, 62.76, 54.91, 52.55, 60.10, 59.83, 52.74]"
      ],
      "metadata": {
        "id": "_xsni_ReY48-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acct = [65.21, 72.35, 67.62, 66.87, 70.47, 74.53, 69.56, 71.95, 64.33, 69.49]"
      ],
      "metadata": {
        "id": "1O0djypFY42x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "?from matplotlib import pyplot as plt\n",
        "plt.xlabel('Train Count')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.title('MNIST-784 dataset')\n",
        "plt.plot(acct)\n",
        "# plt.plot(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "9juZFFLSvnsv",
        "outputId": "8258732c-ba30-4203-8587-b638e9b0fc6a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f31ea771350>]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.xlabel('Train Count')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.title('MNIST-784 dataset')\n",
        "plt.plot(acct)\n",
        "# plt.plot(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "5GOUs8aKY4Yl",
        "outputId": "8bff3e15-36e3-4693-cd00-6c9a385fb090"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f31e4616090>]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "E54drndbZBKt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}